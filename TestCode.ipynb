{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepsparse Engine\n",
    "\n",
    "from deepsparse import Pipeline\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Create YOLO pipeline\n",
    "yolo_pipeline = Pipeline.create(\n",
    "    task=\"yolo\",\n",
    "    model_path=\"model1.onnx\",\n",
    "    class_names=[\"vehicle\", \"numberplate\"],\n",
    "    model_config=None,\n",
    ")\n",
    "\n",
    "# Open the video file\n",
    "vid_cap = cv2.VideoCapture(\"vid.mp4\")\n",
    "\n",
    "# Initialize variables for FPS calculation\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video stream\n",
    "    success, frame = vid_cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Perform YOLO inference on the current frame\n",
    "    inference = yolo_pipeline(images=[frame], iou_thres=0.6, conf_thres=0.25)\n",
    "    boxes = inference.boxes\n",
    "    scores = inference.scores\n",
    "    labels = inference.labels\n",
    "    \n",
    "\n",
    "    # Draw bounding boxes on the frame\n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        x, y, w, h = map(int, box)\n",
    "        class_label = label\n",
    "        confidence = score\n",
    "\n",
    "        # Draw bounding box on the image\n",
    "        color = (0, 255, 0)  # Green color\n",
    "        thickness = 2\n",
    "        cv2.rectangle(frame, (x, y), (w, h), color, thickness)\n",
    "\n",
    "\n",
    "    # Calculate FPS\n",
    "    frame_count += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    fps = frame_count / elapsed_time\n",
    "\n",
    "    # Overlay FPS on the frame\n",
    "    cv2.putText(frame, f\"FPS: {fps:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes and FPS\n",
    "    cv2.imshow('YOLO Output with FPS', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "vid_cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c9eec",
   "metadata": {},
   "source": [
    "## OpenVino-imgsz-384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35997ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights best_openvino_model-150/ --imgsz 360 --nosave --source vid.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "target_size = (384, 384)\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='best_openvino_model-150/', force_reload=True)\n",
    "\n",
    "vid_cap = cv2.VideoCapture(\"vid.mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video stream\n",
    "    success, img = vid_cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    \n",
    "    \n",
    "    # Measure the time before processing the frame\n",
    "\n",
    "    out = Image.fromarray(img)\n",
    "    resize_transform = transforms.Resize(target_size)\n",
    "    resized_image = resize_transform(out)\n",
    "    image_tensor = transforms.ToTensor()(resized_image)\n",
    "    output = image_tensor.reshape(1,3,384,384)\n",
    "    start_frame_time = time.time()\n",
    "\n",
    "    # Perform YOLOv5 inference\n",
    "    results = model(output)\n",
    "    \n",
    "    # Reshape the output to [batch_size, num_anchors, num_attributes] -> [1, 9072, 7]\n",
    "    output_reshaped = results.view(results.size(0), -1, results.size(-1))\n",
    "    fps_text = f\"FPS: {1 / (time.time() - start_frame_time):.2f}\"\n",
    "\n",
    "    # Extract relevant information\n",
    "    confidences = output_reshaped[:, :, 4]  # Confidence scores\n",
    "    class_probs = output_reshaped[:, :, 5:]  # Class probabilities\n",
    "    coordinates = output_reshaped[:, :, :4]  #Coordinates\n",
    "\n",
    "    draw = ImageDraw.Draw(out)\n",
    "    for i in range(coordinates.size(1)):\n",
    "        box = coordinates[0, i].tolist()\n",
    "        confidence = confidences[0, i].item()\n",
    "        if confidence > 0.25:  # Adjust confidence threshold as needed\n",
    "            x, y, w, h = box\n",
    "            x=x*5\n",
    "            w=w*5\n",
    "            y=y*2.8\n",
    "            h=h*3\n",
    "        #x, y, w, h = x * target_size[0], y * target_size[1], w * target_size[0], h * target_size[1]\n",
    "            draw.rectangle([x - w / 2, y - h / 2, x + w / 2, y + h / 2], outline=\"red\", width=1)\n",
    "    \n",
    "    img1 = np.array(out)\n",
    "    # Display FPS\n",
    "    \n",
    "    cv2.putText(img1, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "   \n",
    "    \n",
    "    cv2.imshow('YOLO', img1)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "vid_cap.release()\n",
    "    \n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8444c18",
   "metadata": {},
   "source": [
    "## Openvino-imgsz640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs\\\\train\\\\exp4\\\\weights\\\\last.pt model\n",
    "def func():\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path='best_openvino_model_int8/', force_reload=True)\n",
    "    vid_cap = cv2.VideoCapture(\"vid.mp4\")\n",
    "    vid_cap2 = cv2.VideoCapture(\"vid.mp4\")\n",
    "\n",
    "    # Initialize variables for measuring FPS\n",
    "    frame_times = []\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video stream\n",
    "        success, img = vid_cap.read()\n",
    "        success2, img2 = vid_cap2.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        img = cv2.resize(img, (540,540))\n",
    "        img2 = cv2.resize(img2, (540,540))\n",
    "    \n",
    "        # Measure the time before processing the frame\n",
    "        start_frame_time = time.time()\n",
    "\n",
    "        # Perform YOLOv5 inference\n",
    "#         print(img.shape)\n",
    "        results = model(img)\n",
    "        results2 = model(img2)\n",
    "\n",
    "        # Display the result\n",
    "        output_img = np.squeeze(results.render())\n",
    "        output_img2 = np.squeeze(results2.render())\n",
    "\n",
    "        # Display FPS\n",
    "        fps_text = f\"FPS: {1 / (time.time() - start_frame_time):.2f}\"\n",
    "        cv2.putText(output_img, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(output_img2, fps_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('YOLO', output_img)\n",
    "        cv2.imshow('YOLO2', output_img2)\n",
    "\n",
    "        # Measure the time after processing the frame\n",
    "        end_frame_time = time.time()\n",
    "        frame_times.append(end_frame_time - start_frame_time)\n",
    "        #print(fps_text)\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    vid_cap.release()\n",
    "    vid_cap2.release()\n",
    "    \n",
    "    # Calculate and print the average FPS\n",
    "    avg_fps = len(frame_times) / sum(frame_times)\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4fc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "end_frame_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13534dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702087417.4244957"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_frame_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab701359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
